<!DOCTYPE html>

<html>
<head>
<meta charset="UTF-8">
<link href="style.css" type="text/css" rel="stylesheet">
<title>VPGATHERDQ/VPGATHERQQ — Gather Packed Qword Values Using Signed Dword/Qword Indices </title></head>
<body>
<h1>VPGATHERDQ/VPGATHERQQ — Gather Packed Qword Values Using Signed Dword/Qword Indices</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op/En</th>
<th>64/32 -bit Mode</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>
<p>VEX.DDS.128.66.0F38.W1 90 /r</p>
<p>VPGATHERDQ <em>xmm1, vm32x, xmm2</em></p></td>
<td>RMV</td>
<td>V/V</td>
<td>AVX2</td>
<td>Using dword indices specified in <em>vm32x</em>, gather qword val-ues from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td></tr>
<tr>
<td>
<p>VEX.DDS.128.66.0F38.W1 91 /r</p>
<p>VPGATHERQQ <em>xmm1, vm64x, xmm2</em></p></td>
<td>RMV</td>
<td>V/V</td>
<td>AVX2</td>
<td>Using qword indices specified in <em>vm64x</em>, gather qword val-ues from memory conditioned on mask specified by <em>xmm2</em>. Conditionally gathered elements are merged into <em>xmm1</em>.</td></tr>
<tr>
<td>
<p>VEX.DDS.256.66.0F38.W1 90 /r</p>
<p>VPGATHERDQ <em>ymm1, vm32x, ymm2</em></p></td>
<td>RMV</td>
<td>V/V</td>
<td>AVX2</td>
<td>Using dword indices specified in <em>vm32x</em>, gather qword val-ues from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td></tr>
<tr>
<td>
<p>VEX.DDS.256.66.0F38.W1 91 /r</p>
<p>VPGATHERQQ <em>ymm1, vm64y, ymm2</em></p></td>
<td>RMV</td>
<td>V/V</td>
<td>AVX2</td>
<td>Using qword indices specified in <em>vm64y</em>, gather qword val-ues from memory conditioned on mask specified by <em>ymm2</em>. Conditionally gathered elements are merged into <em>ymm1</em>.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<td>Op/En</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>A</td>
<td>ModRM:reg (r,w)</td>
<td>
<p>BaseReg (R): VSIB:base,</p>
<p>VectorReg(R): VSIB:index</p></td>
<td>VEX.vvvv (r, w)</td>
<td>NA</td></tr></table>
<h2>Description</h2>
<p>The instruction conditionally loads up to 2 or 4 qword values from memory addresses specified by the memory operand (the second operand) and using qword indices. The memory operand uses the VSIB form of the SIB byte to specify a general purpose register operand as the common base, a vector register for an array of indices relative to the base and a constant scale factor.</p>
<p>The mask operand (the third operand) specifies the conditional load operation from each memory address and the corresponding update of each data element of the destination operand (the first operand). Conditionality is speci-fied by the most significant bit of each data element of the mask register. If an element’s mask bit is not set, the corresponding element of the destination register is left unchanged. The width of data element in the destination register and mask register are identical. The entire mask register will be set to zero by this instruction unless the instruction causes an exception.</p>
<p>Using dword indices in the lower half of the mask register, the instruction conditionally loads up to 2 or 4 qword values from the VSIB addressing memory operand, and updates the destination register.</p>
<p>This instruction can be suspended by an exception if at least one element is already gathered (i.e., if the exception is triggered by an element other than the rightmost one with its mask bit set).  When this happens, the destination register and the mask operand are partially updated; those elements that have been gathered are placed into the destination register and have their mask bits set to zero.  If any traps or interrupts are pending from already gath-ered elements, they will be delivered in lieu of the exception; in this case, EFLAG.RF is set to one so an instruction breakpoint is not re-triggered when the instruction is continued.</p>
<p>If the data size and index size are different, part of the destination register and part of the mask register do not correspond to any elements being gathered.  This instruction sets those parts to zero.  It may do this to one or both of those registers even if the instruction triggers an exception, and even if the instruction triggers the exception before gathering any elements.</p>
<p>VEX.128 version: The instruction will gather two qword values.  For dword indices, only the lower two indices in the vector index register are used.</p>
<p>VEX.256 version: The instruction will gather four qword values.  For dword indices, only the lower four indices in the vector index register are used.</p>
<p>Note that:</p>
<h2>Operation</h2>
<pre>DEST ← SRC1;
BASE_ADDR: base register encoded in VSIB addressing;
VINDEX: the vector index register encoded by VSIB addressing;
SCALE: scale factor encoded by SIB:[7:6];
DISP: optional 1, 4 byte displacement;
MASK ← SRC3;</pre>
<p><strong>VPGATHERDQ (VEX.128 version)</strong></p>
<pre>FOR j← 0 to 1
    i ← j * 64;
    IF MASK[63+i] THEN
         MASK[i +63:i] ← FFFFFFFF_FFFFFFFFH; // extend from most significant bit
    ELSE
         MASK[i +63:i] ← 0;
    FI;
ENDFOR
FOR j← 0 to 1
    k ← j * 32;
    i ← j * 64;
    DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX[k+31:k])*SCALE + DISP;
    IF MASK[63+i] THEN
         DEST[i +63:i] ← FETCH_64BITS(DATA_ADDR); // a fault exits the instruction
    FI;
    MASK[i +63:i] ← 0;
ENDFOR
MASK[VLMAX-1:128] ← 0;
DEST[VLMAX-1:128] ← 0;
(non-masked elements of the mask register have the content of respective element  cleared)</pre>
<p><strong>VPGATHERQQ (VEX.128 version)</strong></p>
<pre>FOR j← 0 to 1
    i ← j * 64;
    IF MASK[63+i] THEN
         MASK[i +63:i] ← FFFFFFFF_FFFFFFFFH; // extend from most significant bit
    ELSE
         MASK[i +63:i] ← 0;
    FI;
ENDFOR
FOR j← 0 to 1
    i ←j * 64;
    DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX1[i+63:i])*SCALE + DISP;
    IF MASK[63+i] THEN
         DEST[i +63:i] ← FETCH_64BITS(DATA_ADDR); // a fault exits the instruction
    FI;
    MASK[i +63:i] ← 0;
ENDFOR
MASK[VLMAX-1:128] ← 0;
DEST[VLMAX-1:128] ← 0;
(non-masked elements of the mask register have the content of respective element  cleared)</pre>
<p><strong>VPGATHERQQ (VEX.256 version)</strong></p>
<pre>FOR j← 0 to 3
    i ← j * 64;
    IF MASK[63+i] THEN
         MASK[i +63:i] ← FFFFFFFF_FFFFFFFFH; // extend from most significant bit
    ELSE
         MASK[i +63:i] ← 0;
    FI;
ENDFOR
FOR j← 0 to 3
    i ← j * 64;
    DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX1[i+63:i])*SCALE + DISP;
    IF MASK[63+i] THEN
         DEST[i +63:i] ← FETCH_64BITS(DATA_ADDR); // a fault exits the instruction
    FI;
    MASK[i +63:i] ← 0;
ENDFOR
(non-masked elements of the mask register have the content of respective element  cleared)</pre>
<p><strong>VPGATHERDQ (VEX.256 version)</strong></p>
<pre>FOR j← 0 to 3
    i ← j * 64;
    IF MASK[63+i] THEN
         MASK[i +63:i] ← FFFFFFFF_FFFFFFFFH; // extend from most significant bit
    ELSE
         MASK[i +63:i] ← 0;
    FI;
ENDFOR
FOR j← 0 to 3
    k ← j * 32;
    i ← j * 64;
    DATA_ADDR ← BASE_ADDR + (SignExtend(VINDEX1[k+31:k])*SCALE + DISP;
    IF MASK[63+i] THEN
         DEST[i +63:i] ← FETCH_64BITS(DATA_ADDR); // a fault exits the instruction
    FI;
    MASK[i +63:i] ← 0;
ENDFOR
(non-masked elements of the mask register have the content of respective element  cleared)</pre>
<h2>Intel C/C++ Compiler Intrinsic Equivalent</h2>
<p>VPGATHERDQ: __m128i _mm_i32gather_epi64 (int64 const * base, __m128i index, const int scale);</p>
<p>VPGATHERDQ: __m128i _mm_mask_i32gather_epi64 (__m128i src, int64 const * base, __m128i index, __m128i mask, const int scale);</p>
<p>VPGATHERDQ: __m256i _mm256_i32gather_epi64 ( int64 const * base, __m128i index, const int scale);</p>
<p>VPGATHERDQ: __m256i _mm256_mask_i32gather_epi64 (__m256i src, int64 const * base, __m128i index, __m256i mask, const int scale);</p>
<p>VPGATHERQQ: __m128i _mm_i64gather_epi64 (int64 const * base, __m128i index, const int scale);</p>
<p>VPGATHERQQ: __m128i _mm_mask_i64gather_epi64 (__m128i src, int64 const * base, __m128i index, __m128i mask, const int scale);</p>
<p>VPGATHERQQ: __m256i _mm256_i64gather_epi64 (int64 const * base, __m256i index, const int scale);</p>
<p>VPGATHERQQ: __m256i _mm256_mask_i64gather_epi64 (__m256i src, int64 const * base, __m256i index, __m256i mask, const int scale);</p>
<h2>SIMD Floating-Point Exceptions</h2>
<p>None</p>
<h2>Other Exceptions</h2>
<p>See Exceptions Type 12</p></body></html>
<!DOCTYPE html>

<html>
<head>
<meta charset="UTF-8">
<link href="style.css" type="text/css" rel="stylesheet">
<title>PMULDQ — Multiply Packed Signed Dword Integers </title></head>
<body>
<h1>PMULDQ — Multiply Packed Signed Dword Integers</h1>
<table>
<tr>
<th>Opcode/Instruction</th>
<th>Op/En</th>
<th>64/32 bit Mode Support</th>
<th>CPUID Feature Flag</th>
<th>Description</th></tr>
<tr>
<td>66 0F 38 28 /r PMULDQ <em>xmm1, xmm2/m128</em></td>
<td>RM</td>
<td>V/V</td>
<td>SSE4_1</td>
<td>Multiply the packed signed dword integers in <em>xmm1</em> and <em>xmm2/m128</em> and store the quadword product in <em>xmm1</em>.</td></tr>
<tr>
<td>VEX.NDS.128.66.0F38.WIG 28 /r VPMULDQ <em>xmm1, xmm2, xmm3/m128</em></td>
<td>RVM</td>
<td>V/V</td>
<td>AVX</td>
<td>Multiply packed signed doubleword integers in <em>xmm2</em> by packed signed doubleword integers in <em>xmm3/m128</em>, and store the quadword results in <em>xmm1</em>.</td></tr>
<tr>
<td>VEX.NDS.256.66.0F38.WIG 28 /r VPMULDQ <em>ymm1, ymm2, ymm3/m256</em></td>
<td>RVM</td>
<td>V/V</td>
<td>AVX2</td>
<td>Multiply packed signed doubleword integers in <em>ymm2</em> by packed signed doubleword integers in <em>ymm3/m256</em>, and store the quadword results in <em>ymm1</em>.</td></tr></table>
<h3>Instruction Operand Encoding</h3>
<table>
<tr>
<td>Op/En</td>
<td>Operand 1</td>
<td>Operand 2</td>
<td>Operand 3</td>
<td>Operand 4</td></tr>
<tr>
<td>RM</td>
<td>ModRM:reg (r, w)</td>
<td>ModRM:r/m (r)</td>
<td>NA</td>
<td>NA</td></tr>
<tr>
<td>RVM</td>
<td>ModRM:reg (w)</td>
<td>VEX.vvvv (r)</td>
<td>ModRM:r/m (r)</td>
<td>NA</td></tr></table>
<h2>Description</h2>
<p>Multiplies the first source operand by the second source operand and stores the result in the destination operand.</p>
<p>For PMULDQ and VPMULDQ (VEX.128 encoded version), the second source operand is two packed signed double-word integers stored in the first (low) and third doublewords of an XMM register or a 128-bit memory location. The first source operand is two packed signed doubleword integers stored in the first and third doublewords of an XMM register. The destination contains two packed signed quadword integers stored in an XMM register. For 128-bit memory operands, 128 bits are fetched from memory, but only the first and third doublewords are used in the computation.</p>
<p>For VPMULDQ (VEX.256 encoded version), the second source operand is four packed signed doubleword integers stored in the first (low), third, fifth and seventh doublewords of an YMM register or a 256-bit memory location. The first source operand is four packed signed doubleword integers stored in the first, third, fifth and seventh double-words of an XMM register. The destination contains four packed signed quadword integers stored in an YMM register. For 256-bit memory operands, 256 bits are fetched from memory, but only the first, third, fifth and seventh doublewords are used in the computation.</p>
<p>When a quadword result is too large to be represented in 64 bits (overflow), the result is wrapped around and the low 64 bits are written to the destination element (that is, the carry is ignored).</p>
<p>128-bit Legacy SSE version: The first source and destination operands are XMM registers. The second source operand is an XMM register or a 128-bit memory location. Bits (VLMAX-1:128) of the corresponding YMM destina-tion register remain unchanged.</p>
<p>VEX.128 encoded version: The first source and destination operands are XMM registers. The second source operand is an XMM register or a 128-bit memory location. Bits (VLMAX-1:128) of the destination YMM register are zeroed. VEX.L must be 0, otherwise the instruction will #UD.</p>
<p>VEX.256 encoded version: The second source operand can be an YMM register or a 256-bit memory location. The first source and destination operands are YMM registers.</p>
<h2>Operation</h2>
<p><strong>PMULDQ (128-bit Legacy SSE version)</strong></p>
<pre>DEST[63:0] ← DEST[31:0] * SRC[31:0]
DEST[127:64] ← DEST[95:64] * SRC[95:64]
DEST[VLMAX-1:128] (Unmodified)</pre>
<p><strong>VPMULDQ (VEX.128 encoded version)</strong></p>
<pre>DEST[63:0] ← SRC1[31:0] * SRC2[31:0]
DEST[127:64] ← SRC1[95:64] * SRC2[95:64]
DEST[VLMAX-1:128] ← 0</pre>
<p><strong>VPMULDQ (VEX.256 encoded version)</strong></p>
<pre>DEST[63:0] ← SRC1[31:0] * SRC2[31:0]
DEST[127:64] ← SRC1[95:64] * SRC2[95:64]
DEST[191:128] ← SRC1[159:128] * SRC2[159:128]
DEST[255:192] ← SRC1[223:192] * SRC2[223:192]</pre>
<h2>Intel C/C++ Compiler Intrinsic Equivalent</h2>
<p>(V)PMULDQ:</p>
<p> __m128i _mm_mul_epi32( __m128i a, __m128i b);</p>
<p>VPMULDQ:</p>
<p>__m256i _mm256_mul_epi32( __m256i a, __m256i b);</p>
<h2>Flags Affected</h2>
<p>None.</p>
<h2>SIMD Floating-Point Exceptions</h2>
<p>None.</p>
<h2>Other Exceptions</h2>
<p>See Exceptions Type 5; additionally</p>
<table class="exception-table">
<tr>
<td>#UD</td>
<td>
<p>If VEX.L = 1.</p>
<p>If VEX.vvvv ≠ 1111B.</p></td></tr></table></body></html>